Okay, let's get this packaged up for the move. The goal is to have a self-contained folder you can copy over, install dependencies, and run.
1. Create the Project Context Document
First, I'll provide the content for the catch-up document. Please create a file named PROJECT_CONTEXT.md in the root directory of your project (rella_analytics_db/) and paste the following content into it:
# Rella Analytics DB - Project Context & Status

## Project Goal

To build a web-based analytics dashboard for Rella (a hypothetical MedSpa) to visualize sales data, customer information, and provide actionable insights, including basic forecasting and potential future CRM integration.

## Technology Stack

*   **Backend:** Python (Flask) with SQLite database.
*   **Frontend:** JavaScript (React) using Vite as the build tool.
*   **Charting:** Recharts library.
*   **Mapping:** Deck.gl and Mapbox GL JS (via react-map-gl).
*   **Styling:** CSS, Font Awesome icons.

## Current Status (Key Features Implemented)

*   **Backend:**
    *   SQLite database (`backend/instance/rella_analytics.sqlite`) initialized and seeded with mock/simulated data (locations, categories, services, products, employees, users, transactions, bookings).
    *   **Cost tracking added:** `standard_cost` column added to `services` table and seeded.
    *   API endpoints for:
        *   Authentication (Login, Logout, Status - `/api/v1/auth/...`) - Default user: `admin`/`password`.
        *   Fetching basic data (locations, products, services, etc. - `/api/v1/...`).
        *   Calculating KPIs (`/api/v1/kpis`).
        *   Sales by category (`/api/v1/sales/by_category`).
        *   Profit by category (`/api/v1/profit/by_category`).
        *   Sales over time (`/api/v1/sales/over_time`).
        *   Basic SARIMA sales forecast (`/api/v1/sales/forecast`).
        *   Customer coordinates (`/api/v1/customers/locations`).
*   **Frontend:**
    *   **Login Page:** Functional login connected to the backend.
    *   **Dashboard Page (`/`):**
        *   Displays KPI cards.
        *   Location and Date Range filters (functional, trigger data re-fetch).
        *   Sales Forecast Chart (displays historical + forecast).
        *   Interactive Pie Chart (displays Sales, Profit, Count (Mock), Growth (Mock) via dropdown).
        *   Top Products/Services tables.
        *   Stylized AI Summary card (uses helper function with KPI/Category data).
        *   *Removed:* CSV Upload functionality.
    *   **Map View Page (`/map`):**
        *   Displays map using Deck.gl/Mapbox.
        *   Dropdown to switch between layers:
            *   Customer Locations (Scatterplot - using *backend* data).
            *   Customer Density (Hexagons - using *backend* data).
            *   Sales Value Blocks (GeoJSON - using *static* demo file `/data/napa-vacaville-blocks.json`).
        *   Tooltips and legend implemented.
        *   Currently uses backend data for scatter/hexagon, static file for GeoJSON.
    *   **Reports Page (`/reports`):**
        *   Placeholder page structure implemented.
        *   Uses accordion-style components for different report sections (currently uses sample data).
        *   Includes placeholder for predictive trends.
    *   **Settings Page (`/settings`):**
        *   Placeholder page structure implemented.
        *   Basic forms for User Account (read-only) and CRM Integration (non-functional save).
    *   **Layout:** Sidebar navigation, basic header.
    *   **Ngrok Setup:** `vite.config.js` created with `allowedHosts` and `proxy` configured for `ngrok` access.

## Key Recent Decisions/Changes

*   Switched from basic summary widget to stylized `AISummaryCard`.
*   Removed CSV data upload feature from the dashboard.
*   Refined map view with layer switching (Scatter, Hexagon, GeoJSON).
*   Added cost tracking (`standard_cost`) to services and implemented profit calculation (`/api/v1/profit/by_category`).
*   Added profit view to the dashboard pie chart.
*   Created placeholder pages for Reports (with Accordion UI) and Settings (with basic forms).
*   Configured Vite (`vite.config.js`) for `ngrok` access.

## Next Steps / Areas for Development

*   **Data:** Replace mock/simulated data generation with real data loading (e.g., from Boulevard CRM or updated CSV structure).
*   **Map View:** Connect GeoJSON layer to dynamic backend data if required.
*   **Reports Page:** Implement actual data fetching and display for the accordion reports. Build out predictive analytics section.
*   **Settings Page:** Implement saving/loading settings, change password functionality, actual CRM API calls based on saved credentials.
*   **Boulevard CRM Integration:** Research API, implement backend service calls, integrate data fetching.
*   **Refinement:** Add more robust error handling, loading states, UI polish.

## Running the Application

1.  **Backend:**
    *   Navigate to `backend/`.
    *   Ensure Python environment with dependencies (from `requirements.txt`) is active.
    *   Run: `flask run` (Usually runs on port 5000).
2.  **Frontend:**
    *   Navigate to `frontend/`.
    *   Ensure Node.js dependencies (from `package.json`) are installed (`npm install` or `yarn install`).
    *   Run: `npm run dev` (or `yarn dev`) (Usually runs on port 5173).
3.  **Access:** Open browser to the frontend URL (e.g., `http://localhost:5173`).
v2. Packaging the Project
Here's how to package the project:
Ensure Database is Present: Verify the database file exists at rella_analytics_db/backend/instance/rella_analytics.sqlite. This file contains all your current data and is essential.
Create Archive:
Go to the directory containing your rella_analytics_db folder (i.e., the parent directory).
Right-click on the rella_analytics_db folder.
Choose "Send to" > "Compressed (zipped) folder" (on Windows) or use a similar command on Mac/Linux (e.g., zip -r rella_analytics_db.zip rella_analytics_db or tar -czvf rella_analytics_db.tar.gz rella_analytics_db).
Result: You will have a single file (e.g., rella_analytics_db.zip) containing the entire project structure, including the backend code, frontend code, vite.config.js, the PROJECT_CONTEXT.md file you just created, and crucially, the backend/instance/rella_analytics.sqlite database file. It will not (and should not) include the large node_modules or Python virtual environment folders.
3. Setting up on the New Machine
Copy & Unzip: Copy the archive file (e.g., rella_analytics_db.zip) to the new machine and unzip it. This will recreate the rella_analytics_db folder structure.
Install Prerequisites: Make sure the new machine has:
Python (compatible version, likely 3.9+).
Node.js and npm (or Yarn).
Install Backend Dependencies:
     python -m venv .venv
        # Windows cmd:
        .venv\Scripts\activate
        # Windows Powershell:
        .venv\Scripts\Activate.ps1
        # Mac/Linux:
        source .venv/bin/activate
Open a terminal/command prompt.
Navigate into the project: cd path/to/rella_analytics_db/backend


Install dependencies: pip install -r requirements.txt (Assuming you have a requirements.txt file. If not, you'll need to create one based on the installed packages or install them manually: pip install Flask Flask-Cors pandas statsmodels Flask-Login Werkzeug click python-dotenv)
Install Frontend Dependencies:
Open another terminal/command prompt.
Navigate into the frontend: cd path/to/rella_analytics_db/frontend
Install dependencies: npm install (or yarn install)
Run the Application:
Backend: In the first terminal (in backend/, with venv active), run: flask run
Frontend: In the second terminal (in frontend/), run: npm run dev (or yarn dev)
Access: Open a web browser to the frontend URL (usually http://localhost:5173).
You should now have the application running on the new machine with the same code and data as before. The PROJECT_CONTEXT.md file will be there for your reference.